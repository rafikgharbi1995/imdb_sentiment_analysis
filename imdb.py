import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import streamlit as st
import io

# T√©l√©chargement des ressources NLTK
nltk.download('stopwords')
nltk.download('punkt')


class IMDBReviewClassifier:
    def __init__(self):
        self.df = None
        self.vectorizer = None
        self.model = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None

    def load_and_explore_data(self, file_path='IMDB Dataset.csv'):
        """Charge et explore le dataset"""
        st.header("üìä Chargement et Exploration des Donn√©es")

        # Chargement des donn√©es
        self.df = pd.read_csv(file_path)

        # Affichage des informations de base
        st.subheader("Aper√ßu du Dataset")
        st.write(f"**Nombre total de critiques :** {len(self.df)}")
        st.write(f"**Colonnes :** {list(self.df.columns)}")

        # Distribution des sentiments
        st.subheader("Distribution des Sentiments")
        sentiment_counts = self.df['sentiment'].value_counts()
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

        # Diagramme en barres
        sentiment_counts.plot(kind='bar', ax=ax1, color=['green', 'red'])
        ax1.set_title('Distribution des Sentiments')
        ax1.set_xlabel('Sentiment')
        ax1.set_ylabel('Nombre de Critiques')

        # Diagramme circulaire
        ax2.pie(sentiment_counts.values, labels=sentiment_counts.index,
                autopct='%1.1f%%', colors=['green', 'red'])
        ax2.set_title('R√©partition des Sentiments')

        st.pyplot(fig)

        # Longueur des critiques
        self.df['review_length'] = self.df['review'].apply(len)
        st.subheader("Longueur des Critiques")
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.hist(self.df['review_length'], bins=50, alpha=0.7, color='skyblue')
        ax.set_xlabel('Longueur des Critiques')
        ax.set_ylabel('Fr√©quence')
        ax.set_title('Distribution de la Longueur des Critiques')
        st.pyplot(fig)

        # Statistiques descriptives
        st.write("**Statistiques descriptives :**")
        st.write(f"- Longueur moyenne : {self.df['review_length'].mean():.2f} caract√®res")
        st.write(f"- Longueur maximale : {self.df['review_length'].max()} caract√®res")
        st.write(f"- Longueur minimale : {self.df['review_length'].min()} caract√®res")

        return self.df

    def preprocess_text(self, text):
        """Pr√©traite le texte"""
        # Conversion en minuscules
        text = text.lower()

        # Suppression des balises HTML
        text = re.sub(r'<.*?>', '', text)

        # Suppression des URLs
        text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)

        # Suppression de la ponctuation et des caract√®res sp√©ciaux
        text = re.sub(r'[^\w\s]', '', text)

        # Tokenization
        tokens = word_tokenize(text)

        # Suppression des stopwords
        stop_words = set(stopwords.words('english'))
        tokens = [token for token in tokens if token not in stop_words and len(token) > 2]

        return ' '.join(tokens)

    def preprocess_data(self):
        """Pr√©traite l'ensemble des donn√©es"""
        st.header("üîß Pr√©traitement des Donn√©es")

        # Application du pr√©traitement
        st.write("Pr√©traitement des critiques en cours...")
        self.df['cleaned_review'] = self.df['review'].apply(self.preprocess_text)

        # Encodage des labels
        self.df['sentiment_encoded'] = self.df['sentiment'].map({'positive': 1, 'negative': 0})

        # Vectorisation TF-IDF
        st.write("Vectorisation TF-IDF en cours...")
        self.vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
        X = self.vectorizer.fit_transform(self.df['cleaned_review'])

        # Division des donn√©es
        y = self.df['sentiment_encoded']
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        st.write(f"**Forme des donn√©es d'entra√Ænement :** {self.X_train.shape}")
        st.write(f"**Forme des donn√©es de test :** {self.X_test.shape}")

        # Aper√ßu des caract√©ristiques TF-IDF
        st.subheader("Caract√©ristiques TF-IDF")
        feature_names = self.vectorizer.get_feature_names_out()
        st.write(f"**Nombre de caract√©ristiques :** {len(feature_names)}")
        st.write("**Top 20 caract√©ristiques :**")
        st.write(feature_names[:20])

        return X, y

    def build_model(self, input_dim):
        """Construit le mod√®le de r√©seau neuronal"""
        st.header("üß† Construction du Mod√®le")

        model = Sequential([
            Dense(512, activation='relu', input_shape=(input_dim,)),
            Dropout(0.5),
            Dense(256, activation='relu'),
            Dropout(0.4),
            Dense(128, activation='relu'),
            Dropout(0.3),
            Dense(64, activation='relu'),
            Dropout(0.2),
            Dense(1, activation='sigmoid')
        ])

        # Compilation du mod√®le
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )

        st.write("**Architecture du mod√®le :**")
        model_summary = []
        model.summary(print_fn=lambda x: model_summary.append(x))
        st.text("\n".join(model_summary))

        self.model = model
        return model

    def train_model(self, epochs=10, batch_size=32):
        """Entra√Æne le mod√®le"""
        st.header("üèãÔ∏è‚Äç‚ôÇÔ∏è Entra√Ænement du Mod√®le")

        # Callback pour l'arr√™t anticip√©
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )

        # Entra√Ænement
        st.write("D√©but de l'entra√Ænement...")
        history = self.model.fit(
            self.X_train.toarray(), self.y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )

        # Visualisation de l'entra√Ænement
        self.plot_training_history(history)

        return history

    def plot_training_history(self, history):
        """Visualise l'historique d'entra√Ænement"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

        # Perte
        ax1.plot(history.history['loss'], label='Perte Entra√Ænement')
        ax1.plot(history.history['val_loss'], label='Perte Validation')
        ax1.set_title('√âvolution de la Perte')
        ax1.set_xlabel('√âpoques')
        ax1.set_ylabel('Perte')
        ax1.legend()

        # Pr√©cision
        ax2.plot(history.history['accuracy'], label='Pr√©cision Entra√Ænement')
        ax2.plot(history.history['val_accuracy'], label='Pr√©cision Validation')
        ax2.set_title('√âvolution de la Pr√©cision')
        ax2.set_xlabel('√âpoques')
        ax2.set_ylabel('Pr√©cision')
        ax2.legend()

        st.pyplot(fig)

    def evaluate_model(self):
        """√âvalue le mod√®le"""
        st.header("üìà √âvaluation du Mod√®le")

        # √âvaluation sur les donn√©es de test
        test_loss, test_accuracy, test_precision, test_recall = self.model.evaluate(
            self.X_test.toarray(), self.y_test, verbose=0
        )

        st.subheader("Performance sur les Donn√©es de Test")
        st.write(f"**Perte :** {test_loss:.4f}")
        st.write(f"**Pr√©cision :** {test_accuracy:.4f}")
        st.write(f"**Pr√©cision (metric) :** {test_precision:.4f}")
        st.write(f"**Rappel :** {test_recall:.4f}")

        # Pr√©dictions
        y_pred_proba = self.model.predict(self.X_test.toarray())
        y_pred = (y_pred_proba > 0.5).astype(int)

        # Rapport de classification
        st.subheader("Rapport de Classification")
        report = classification_report(self.y_test, y_pred, target_names=['Negative', 'Positive'])
        st.text(report)

        # Matrice de confusion
        st.subheader("Matrice de Confusion")
        cm = confusion_matrix(self.y_test, y_pred)
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Negative', 'Positive'],
                    yticklabels=['Negative', 'Positive'])
        ax.set_xlabel('Pr√©dictions')
        ax.set_ylabel('Vraies √©tiquettes')
        ax.set_title('Matrice de Confusion')
        st.pyplot(fig)

        return test_accuracy

    def predict_sentiment(self, text):
        """Pr√©dit le sentiment d'une nouvelle critique"""
        # Pr√©traitement
        cleaned_text = self.preprocess_text(text)

        # Vectorisation
        text_vectorized = self.vectorizer.transform([cleaned_text])

        # Pr√©diction
        prediction_proba = self.model.predict(text_vectorized.toarray())[0][0]
        sentiment = "Positive" if prediction_proba > 0.5 else "Negative"
        confidence = prediction_proba if prediction_proba > 0.5 else 1 - prediction_proba

        return sentiment, confidence, prediction_proba


def main():
    st.set_page_config(
        page_title="Classificateur de Critiques IMDb",
        page_icon="üé¨",
        layout="wide"
    )

    st.title("üé¨ Classificateur de Critiques de Films IMDb")
    st.markdown("""
    Ce syst√®me utilise un r√©seau neuronal pour classer les critiques de films comme **positives** ou **n√©gatives**.
    """)

    # Initialisation du classificateur
    if 'classifier' not in st.session_state:
        st.session_state.classifier = IMDBReviewClassifier()

    classifier = st.session_state.classifier

    # Sidebar pour la navigation
    st.sidebar.title("Navigation")
    section = st.sidebar.radio(
        "S√©lectionnez une section :",
        ["Exploration des Donn√©es", "Pr√©traitement", "Construction du Mod√®le",
         "Entra√Ænement", "√âvaluation", "Pr√©diction"]
    )

    # Chargement des donn√©es
    if classifier.df is None:
        try:
            classifier.load_and_explore_data()
        except FileNotFoundError:
            st.error(
                "Fichier 'IMDB Dataset.csv' non trouv√©. Veuillez vous assurer qu'il est dans le r√©pertoire courant.")
            return

    if section == "Exploration des Donn√©es":
        st.header("üìä Exploration des Donn√©es")

        # Aper√ßu des donn√©es
        st.subheader("Aper√ßu des Donn√©es")
        st.dataframe(classifier.df.head(10))

        # Exemples de critiques
        st.subheader("Exemples de Critiques")
        col1, col2 = st.columns(2)

        with col1:
            st.write("**Critique Positive :**")
            positive_review = classifier.df[classifier.df['sentiment'] == 'positive'].iloc[0]['review']
            st.text_area("", positive_review[:500] + "...", height=200)

        with col2:
            st.write("**Critique N√©gative :**")
            negative_review = classifier.df[classifier.df['sentiment'] == 'negative'].iloc[0]['review']
            st.text_area("", negative_review[:500] + "...", height=200)

    elif section == "Pr√©traitement":
        classifier.preprocess_data()

        # Aper√ßu avant/apr√®s pr√©traitement
        st.subheader("Exemple de Pr√©traitement")
        sample_review = classifier.df.iloc[0]
        col1, col2 = st.columns(2)

        with col1:
            st.write("**Avant pr√©traitement :**")
            st.text_area("", sample_review['review'][:500] + "...", height=200)

        with col2:
            st.write("**Apr√®s pr√©traitement :**")
            st.text_area("", sample_review['cleaned_review'][:500] + "...", height=200)

    elif section == "Construction du Mod√®le":
        if classifier.X_train is None:
            st.warning("Veuillez d'abord pr√©traiter les donn√©es dans la section 'Pr√©traitement'.")
        else:
            classifier.build_model(classifier.X_train.shape[1])

    elif section == "Entra√Ænement":
        if classifier.model is None:
            st.warning("Veuillez d'abord construire le mod√®le dans la section 'Construction du Mod√®le'.")
        else:
            st.sidebar.subheader("Param√®tres d'Entra√Ænement")
            epochs = st.sidebar.slider("Nombre d'√©poques", 1, 20, 10)
            batch_size = st.sidebar.slider("Taille du lot", 16, 128, 32)

            if st.button("D√©marrer l'Entra√Ænement"):
                with st.spinner("Entra√Ænement en cours..."):
                    classifier.train_model(epochs=epochs, batch_size=batch_size)

    elif section == "√âvaluation":
        if classifier.model is None:
            st.warning("Veuillez d'abord entra√Æner le mod√®le dans la section 'Entra√Ænement'.")
        else:
            classifier.evaluate_model()

    elif section == "Pr√©diction":
        st.header("üîÆ Pr√©diction de Sentiment")

        st.markdown("""
        Entrez une critique de film ci-dessous pour pr√©dire si elle est **positive** ou **n√©gative**.
        """)

        # Zone de texte pour la pr√©diction
        user_review = st.text_area(
            "Votre critique de film :",
            height=200,
            placeholder="Entrez votre critique de film ici..."
        )

        if st.button("Analyser le Sentiment") and user_review:
            with st.spinner("Analyse en cours..."):
                sentiment, confidence, proba = classifier.predict_sentiment(user_review)

                # Affichage des r√©sultats
                st.subheader("R√©sultat de l'Analyse")

                col1, col2 = st.columns(2)

                with col1:
                    if sentiment == "Positive":
                        st.success(f"**Sentiment : {sentiment}**")
                    else:
                        st.error(f"**Sentiment : {sentiment}**")

                    st.write(f"**Confiance :** {confidence:.2%}")
                    st.write(f"**Score de probabilit√© :** {proba:.4f}")

                with col2:
                    # Barre de progression
                    fig, ax = plt.subplots(figsize=(8, 2))
                    ax.barh(['Sentiment'], [proba * 100], color='green' if sentiment == 'Positive' else 'red')
                    ax.set_xlim(0, 100)
                    ax.set_xlabel('Probabilit√© (%)')
                    ax.set_title('Score de Confiance')
                    st.pyplot(fig)

        # Exemples pr√©d√©finis
        st.subheader("Exemples de Test")
        example_reviews = [
            "This movie was absolutely fantastic! The acting was superb and the plot was engaging from start to finish.",
            "Terrible movie. Poor acting, boring story, and awful direction. I want my money back.",
            "The cinematography was beautiful but the characters were poorly developed and the story was predictable.",
            "An amazing performance by the lead actor. The movie kept me on the edge of my seat throughout."
        ]

        for i, example in enumerate(example_reviews):
            if st.button(f"Tester l'exemple {i + 1}"):
                st.session_state.user_review = example
                st.experimental_rerun()


if __name__ == "__main__":
    main()